{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc91d7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from matplotlib.pyplot import xticks\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import RFECV\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "from sklearn.metrics import mean_squared_error\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c232bb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "df = pd.DataFrame(pd.read_csv(r'..\\Project\\CarPrice.csv'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67e683c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#car_ID is not needed\n",
    "df.drop(columns=[\"car_ID\"], axis=1, inplace=True)\n",
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c76b126",
   "metadata": {},
   "source": [
    "We had 26 columns and 205 rows in the data. we dropped column \"Car ID\" as it is not needed for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0612e9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's plot the price to see distibution\n",
    "sns.histplot(df['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c845cc",
   "metadata": {},
   "source": [
    "from the graph, we can see that distribution of the price  is right-skewed. which suggest that log-linear regression model might  fit better in comparison to simple linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ca3187",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.CarName.values[0:10]\n",
    "df['Brand'] = df.CarName.str.split(' ').str.get(0).str.upper()\n",
    "df['Model'] = df.CarName.str.split(' ').str.get(1).str.upper()\n",
    "len(set(df.Brand.values))\n",
    "df.drop(columns=[\"CarName\"], axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2ca42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Brand.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe4fecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have 5 car brand names which is spelled incorrectly. \n",
    "Brand_dict = {\n",
    "    'TOYOUTA': 'TOYOTA',\n",
    "    'MAXDA': 'MAZDA',\n",
    "    'PORSCHE': 'PORCSHCE',\n",
    "    'VOKSWAGEN': 'VOLKSWAGEN',\n",
    "    'VW': 'VOLKSWAGEN',\n",
    "}\n",
    "\n",
    "# Correcting brand name in dataframe\n",
    "df['Brand'] = df['Brand'].map(Brand_dict).fillna(df['Brand'])\n",
    "# Let's test again if all corrected\n",
    "df.Brand.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4072f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RiskRate'] = df['symboling'].apply(lambda x : \"High Risk\" if x > 1 \n",
    "                                                     else (\"Medium Risk\" if 0 <= x <= 1\n",
    "                                                        else \"Low Risk\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32444efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(80, 60))\n",
    "fig.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "\n",
    "charts = [\n",
    "    {'title': \"Brand Distribution\", 'x': 'Brand', 'y': 'price'},\n",
    "    {'title': \"Fuel Type Distribution\", 'x': 'fueltype', 'y': 'price'},\n",
    "    {'title': \"Aspiration Distribution\", 'x': 'aspiration', 'y': 'price'},\n",
    "    {'title': \"Door Number Distribution\", 'x': 'doornumber', 'y': 'price'},\n",
    "    {'title': \"Car Body Distribution\", 'x': 'carbody', 'y': 'price'},\n",
    "    {'title': \"Drivewheel Distribution\", 'x': 'drivewheel', 'y': 'price'},\n",
    "    {'title': \"Engine Location Distribution\", 'x': 'enginelocation', 'y': 'price'},\n",
    "    {'title': \"Engine Type Distribution\", 'x': 'enginetype', 'y': 'price'},\n",
    "    {'title': \"Cylinder Number Distribution\", 'x': 'cylindernumber', 'y': 'price'},\n",
    "    {'title': \"Fuel System Distribution\", 'x': 'fuelsystem', 'y': 'price'},\n",
    "    {'title': \"Risk Rate Distribution\", 'x': 'RiskRate', 'y': 'price'}\n",
    "]\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        if counter < len(charts):\n",
    "            chart = charts[counter]\n",
    "            plt.subplot(3, 3, counter+1)\n",
    "            plt.title(chart['title'], fontsize=40)\n",
    "            sns.barplot(x=chart['x'], y=chart['y'], data=df)\n",
    "            plt.xlabel(chart['x'], fontsize=35)\n",
    "            plt.ylabel(chart['y'], fontsize=35)\n",
    "            plt.xticks(fontsize=40, rotation=90)\n",
    "        else:\n",
    "            axes[i, j].axis('off')\n",
    "        counter += 1\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (190, 180)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5383f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns = ['wheelbase', 'carlength', 'carwidth', 'carheight', 'curbweight', 'enginesize',\n",
    "           'boreratio', 'stroke', 'compressionratio', 'horsepower', 'peakrpm',\n",
    "           'citympg', 'highwaympg']\n",
    "\n",
    "\n",
    "num_plots = len(columns)\n",
    "num_cols = 3\n",
    "num_rows = (num_plots - 1) // num_cols + 1\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(12, 12))\n",
    "plt.subplots_adjust(hspace=0.8)\n",
    "plt.subplots_adjust(wspace=0.8)\n",
    "\n",
    "for i, col in enumerate(columns):\n",
    "    row = i // num_cols\n",
    "    col = df[col]  \n",
    "    \n",
    "    ax = axes[row, i % num_cols]\n",
    "    ax.set_title(col.name.capitalize() + \" Distribution\")\n",
    "    sns.scatterplot(x=col, y='price', data=df, ax=ax)\n",
    "\n",
    "\n",
    "if num_plots % num_cols != 0:\n",
    "    for j in range(num_plots % num_cols, num_cols):\n",
    "        fig.delaxes(axes[-1, j])\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05f9631",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16, 10))\n",
    "sns.heatmap(df.corr(), annot = True, cmap=\"YlGnBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b6e5bc",
   "metadata": {},
   "source": [
    "As it seems from corellation matrix, there are independent variables which have significant correlation between each other. So using all of them in regression model will mislead the result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32052cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outlier treatment of quantitative variables\n",
    "#listing all the numeric variables in dataframe carprice\n",
    "categorical_columns = df.select_dtypes(include=['object', 'category']).columns\n",
    "continues_columns = df.select_dtypes(exclude=['object', 'category']).columns\n",
    "print(\"\\033[1mCategorical\\033[0m\")\n",
    "print(categorical_columns)\n",
    "print(\"\\033[1mContinues\\033[0m\")\n",
    "print(continues_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68f8476",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for outliers in wheelbase column and removing them \n",
    "for column in continues_columns:\n",
    "    # Calculate the lower and upper boundaries for outliers\n",
    "    lb = df[column].quantile(0.25) - 1.5 * (df[column].quantile(0.75) - df[column].quantile(0.25))\n",
    "    ub = df[column].quantile(0.75) + 1.5 * (df[column].quantile(0.75) - df[column].quantile(0.25))\n",
    "    \n",
    "    # Assign highest and lowest values to outliers\n",
    "    df.loc[df[column] < lb, column] = lb\n",
    "    df.loc[df[column] > ub, column] = ub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa68ad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for any NA induction during outlier treatment\n",
    "df['price'].isnull().sum() # if output is 0, it means there is not any NaN value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582e5f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncoder cateogerical values  \n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "Edata = encoder.fit_transform(df[categorical_columns])\n",
    "E_df = pd.DataFrame(Edata, columns=encoder.get_feature_names_out(categorical_columns))\n",
    "\n",
    "#Scaling the continuous columns\n",
    "scaler = StandardScaler()\n",
    "Sdata = scaler.fit_transform(df[continues_columns])\n",
    "S_df=pd.DataFrame(Sdata, columns=continues_columns)\n",
    "# Concatenate the encoded data with the numerical data from df\n",
    "df_fit = pd.concat([S_df, E_df], axis=1)\n",
    "print(df_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae16c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's randomly divide data two part -70% training 30% testing\n",
    "df_random = df_fit.sample(frac=1, random_state=42)\n",
    "Div_index = int(0.7 * len(df_random))\n",
    "train_df = df_random[:Div_index]\n",
    "test_df = df_random[Div_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e53f27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#LInear Regression modelling\n",
    "y = train_df['price']\n",
    "X = train_df.drop('price', axis=1)\n",
    "\n",
    "# Model with all features\n",
    "model_1 = sm.OLS(y, X)\n",
    "result = model_1.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf5543a",
   "metadata": {},
   "source": [
    "As we see, model R2 is 1. which means model perfectly explain price, while Adj. R-squared is nan. it is result of lack of degree of freedom - we have 143 observarions and 217 different independed variables. We should elliminate all the variables which we can not reject hypotesis that their coefficient is not 0. \n",
    "for that purpose we use stepwise_regression library. ( jupyter is unable to install and call functions of stepwise_regression. so, we manually added them here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd62f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library taken from https://github.com/AakkashVijayakumar/stepwise-regression/blob/master/stepwise_regression/step_reg.py\n",
    "def forward_regression(X, y,\n",
    "                       threshold_in,\n",
    "                       verbose=False):\n",
    "    initial_list = []\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        if not changed:\n",
    "            break\n",
    "\n",
    "    return included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fcc826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step_wise selection of significant features\n",
    "dfc = train_df\n",
    "\n",
    "# Separate features and target\n",
    "X = dfc.drop('price', axis=1)\n",
    "y = dfc['price']\n",
    "forward_regression = forward_regression(X, y, 0.025)\n",
    "print(\"Selected Features (forward_regression):\")\n",
    "print(forward_regression)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3519f149",
   "metadata": {},
   "source": [
    "Below features are selected as a result of Step_wise selection:\n",
    "['enginesize', 'curbweight', 'Brand_PORCSHCE', 'Brand_BMW', 'cylindernumber_four', 'Brand_BUICK', 'horsepower', 'Model_RX-7', 'carbody_sedan', 'Model_DAYZ', 'carbody_convertible', 'wheelbase', 'highwaympg', 'Brand_SAAB', 'Model_504(SW)', 'Model_304', 'Model_CENTURY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cd7350",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model_2 - All the features selected from step_wise selection\n",
    "y = train_df['price']\n",
    "X2= train_df.loc[:,forward_regression]\n",
    "\n",
    "# Model with all features\n",
    "model_2 = sm.OLS(y, X2)\n",
    "result2 = model_2.fit()\n",
    "result2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dd34c4",
   "metadata": {},
   "source": [
    "R^2 of the model is 95% -high but we still have features with insignificant  coefficients. so, we remove variables with highest p value - enginesize in Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab806106",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 3\n",
    "y = train_df['price']\n",
    "X3= X2.drop('enginesize', axis=1)\n",
    "model_3 = sm.OLS(y, X3)\n",
    "result3 = model_3.fit()\n",
    "result3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dfe5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 4\n",
    "y = train_df['price']\n",
    "X4= X3.drop('Model_504(SW)', axis=1)\n",
    "model_4 = sm.OLS(y, X4)\n",
    "result4 = model_4.fit()\n",
    "result4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff07671",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 5\n",
    "y = train_df['price']\n",
    "X5= X4.drop('Model_304', axis=1)\n",
    "model_5 = sm.OLS(y, X5)\n",
    "result5 = model_5.fit()\n",
    "result5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d530e22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 6\n",
    "y = train_df['price']\n",
    "X6= X5.drop('Model_CENTURY', axis=1)\n",
    "model_6 = sm.OLS(y, X6)\n",
    "result6 = model_6.fit()\n",
    "result6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee428cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 7\n",
    "y = train_df['price']\n",
    "X7= X6.drop('highwaympg', axis=1)\n",
    "model_7 = sm.OLS(y, X7)\n",
    "result7 = model_7.fit()\n",
    "result7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc82b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 8\n",
    "y = train_df['price']\n",
    "X8= X7.drop('Brand_SAAB', axis=1)\n",
    "model_8 = sm.OLS(y, X8)\n",
    "result8 = model_8.fit()\n",
    "result8.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73836461",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 9\n",
    "y = train_df['price']\n",
    "X9= X8.drop('wheelbase', axis=1)\n",
    "model_9 = sm.OLS(y, X9)\n",
    "result9 = model_9.fit()\n",
    "result9.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8dbf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 10\n",
    "y = train_df['price']\n",
    "X10= X9.drop('carbody_convertible', axis=1)\n",
    "model_10 = sm.OLS(y, X10)\n",
    "result10 = model_10.fit()\n",
    "result10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a7cce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the target variable\n",
    "Columns=X10.columns\n",
    "y_test = test_df['price']\n",
    "X_test= test_df[Columns]\n",
    "y_pred = result10.predict(X_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "mse = np.mean((y_test - y_pred) ** 2)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c528ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dflr=train_df\n",
    "# Separate features and target\n",
    "X =dflr.drop('price', axis=1)\n",
    "y = dflr['price']\n",
    "\n",
    "# Create and fit a linear regression model\n",
    "model1 = LinearRegression()\n",
    "model1.fit(X, y)\n",
    "\n",
    "# For below part we asked for help of ChatGPT\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "\n",
    "# Perform feature selection with cross-validation\n",
    "rfecv = RFECV(estimator=model)\n",
    "X_selected = rfecv.fit_transform(X, y)\n",
    "\n",
    "# Perform cross-validation on the selected features\n",
    "cv_scores = cross_val_score(model, X_selected, y, cv=5, scoring='r2')\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Average R^2:\", cv_scores.mean())\n",
    "\n",
    "# Get the selected features \n",
    "selected_features = X.columns[rfecv.support_]\n",
    "\n",
    "\n",
    "# Print the selected features\n",
    "print(\"Selected Features:\", selected_features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3e7b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t=test_df.drop('price', axis=1)\n",
    "x_test=rfecv.transform(x_t)\n",
    "y_test=test_df['price']\n",
    "model.fit(x_test, y_test)\n",
    "ypredict=model.predict(x_test)\n",
    "mse = mean_squared_error(y_test, ypredict)\n",
    "print(\"RMSE:\", mse**0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
